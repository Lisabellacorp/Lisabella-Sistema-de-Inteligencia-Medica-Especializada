import os
import time
from concurrent.futures import ThreadPoolExecutor, TimeoutError
from groq import Groq

class GroqClient:
    def __init__(self):
        api_key = os.environ.get("GROQ_API_KEY")
        if not api_key:
            raise Exception("GROQ_API_KEY no configurada")
        self.client = Groq(api_key=api_key)
        self.model = os.environ.get("GROQ_MODEL", "llama-3.1-70b-versatile")
        self.temp = float(os.environ.get("GROQ_TEMP", "0.3"))
        self.max_retries = 3
        self.base_retry_delay = 2
        self.api_timeout = 300

    def _classify_question_type(self, question: str) -> str:
        q_lower = (question or "").lower()
        if any(word in q_lower for word in ["dosis", "calcular", "cuanto", "cu√°nto", "que es", "qu√© es", "define", "definici√≥n", "definicion", "posologia", "posolog√≠a"]):
            return "operativa"
        if q_lower.count("‚Ä¢") >= 3 or q_lower.count("\n") >= 3 or any(kw in q_lower for kw in ["incluyendo:", "incluye:"]):
            return "academica"
        return "estandar"

    def _log_token_usage(self, prompt_tokens, completion_tokens, domain):
        total = (prompt_tokens or 0) + (completion_tokens or 0)
        timestamp = time.strftime("%Y-%m-%d %H:%M:%S")
        print(f"üìä [{timestamp}] Tokens: P={prompt_tokens} + C={completion_tokens} = {total} | Dominio: {domain}")
        try:
            os.makedirs("logs", exist_ok=True)
            with open("logs/token_usage.log", "a", encoding="utf-8") as f:
                f.write(f"{timestamp}|{domain}|{prompt_tokens}|{completion_tokens}|{total}\n")
        except Exception:
            pass

    def generate_stream(self, question, domain, special_command=None):
        system_msg = self._build_system_prompt(domain, special_command)
        user_msg = self._build_user_prompt(question, domain, special_command)
        question_type = self._classify_question_type(question)
        if question_type == "operativa":
            max_tokens, temperature = 800, 0.1
        elif question_type == "academica":
            max_tokens, temperature = 8000, 0.3
        else:
            max_tokens, temperature = 3000, 0.3
        if special_command in ["revision_nota", "correccion_nota", "elaboracion_nota", "valoracion"]:
            max_tokens, temperature = 12000, 0.1
        try:
            stream = self.client.chat.completions.create(model=self.model, messages=[{"role": "system", "content": system_msg}, {"role": "user", "content": user_msg}], temperature=temperature, max_tokens=max_tokens, stream=True)
            chunk_count, accumulated_content = 0, ""
            for event in stream:
                choices = getattr(event, "choices", [])
                if choices:
                    delta = getattr(choices[0].delta, "content", None)
                    if delta:
                        chunk_count += 1
                        accumulated_content += delta
                        yield delta
            self._log_token_usage(len(system_msg + user_msg) // 4, len(accumulated_content) // 4, domain)
            yield "__STREAM_DONE__"
        except Exception as e:
            error_str, error_lower = str(e), str(e).lower()
            if "429" in error_str or "rate" in error_lower:
                yield "\n\n‚è≥ **Sistema Saturado**\n\nEspera 1-2 minutos."
            elif "timeout" in error_lower:
                yield "\n\n‚è±Ô∏è **Timeout**\n\nIntenta con pregunta m√°s breve."
            elif "401" in error_str or "auth" in error_lower:
                yield "\n\n‚ö†Ô∏è **Error autenticaci√≥n**\n\nContacta administrador."
            else:
                yield f"\n\n‚ö†Ô∏è **Error**\n\n{error_str[:200]}"
            yield "__STREAM_DONE__"

    def generate(self, question, domain, special_command=None):
        question_type = self._classify_question_type(question)
        max_tokens = 800 if question_type == "operativa" else (8000 if question_type == "academica" else 3000)
        if special_command in ["revision_nota", "correccion_nota", "elaboracion_nota", "valoracion"]:
            max_tokens = 12000
        for attempt in range(self.max_retries):
            try:
                with ThreadPoolExecutor(max_workers=1) as executor:
                    return executor.submit(self._call_groq_api, question, domain, special_command, max_tokens).result(timeout=self.api_timeout)
            except TimeoutError:
                if attempt < self.max_retries - 1:
                    time.sleep(self.base_retry_delay)
                else:
                    return "‚è±Ô∏è **Timeout**\nReformula tu pregunta."
            except Exception as e:
                if attempt < self.max_retries - 1 and ("429" in str(e) or "rate" in str(e).lower()):
                    time.sleep(self.base_retry_delay * (2 ** attempt))
                else:
                    return f"‚ö†Ô∏è **Error**: {str(e)[:200]}"
        return "‚è≥ **Sistema Saturado**"

    def _call_groq_api(self, question, domain, special_command, max_tokens=3000):
        system_msg = self._build_system_prompt(domain, special_command)
        user_msg = self._build_user_prompt(question, domain, special_command)
        temperature = 0.1 if special_command in ["revision_nota", "correccion_nota", "elaboracion_nota", "valoracion"] else self.temp
        response = self.client.chat.completions.create(model=self.model, messages=[{"role": "system", "content": system_msg}, {"role": "user", "content": user_msg}], temperature=temperature, max_tokens=max_tokens)
        usage = getattr(response, "usage", None)
        if usage:
            try:
                self._log_token_usage(getattr(usage, "prompt_tokens", 0), getattr(usage, "completion_tokens", 0), domain)
            except:
                pass
        return response.choices[0].message.content

    def generate_chunk(self, prompt: str, domain: str, max_tokens: int = 1200):
        system_msg = self._get_base_prompt(domain)
        response = self.client.chat.completions.create(model=self.model, messages=[{"role": "system", "content": system_msg}, {"role": "user", "content": prompt}], temperature=self.temp, max_tokens=max_tokens)
        return response.choices[0].message.content

    def _build_system_prompt(self, domain, special_command=None):
        if special_command == "revision_nota":
            return """Eres auditor m√©dico JCI/COFEPRIS. Eval√∫a nota con est√°ndares completos: datos paciente, motivo consulta, padecimiento, antecedentes, exploraci√≥n, diagn√≥stico, plan, legal. Formato: Componentes Presentes, Faltantes, Errores, Cumplimiento %, Recomendaciones."""
        elif special_command == "correccion_nota":
            return """Corrector notas m√©dicas JCI/COFEPRIS. Detecta errores formato, ortograf√≠a m√©dica, dosis, claridad. Formato: Errores Detectados, Nota Corregida, Sugerencias. NO inventes datos."""
        elif special_command == "elaboracion_nota":
            return """Genera plantilla SOAP completa: Datos Documento, Datos Paciente, Subjetivo (motivo/padecimiento/antecedentes), Objetivo (vitales/exploraci√≥n), An√°lisis (diagn√≥stico/justificaci√≥n), Plan (estudios/tratamiento/pron√≥stico/seguimiento). Marca [COMPLETAR] si falta info."""
        elif special_command == "valoracion":
            return """M√©dico consultor Mayo/UpToDate. Proporciona: Resumen Caso, Hip√≥tesis Diagn√≥sticas (probable + 3 diferenciales con justificaci√≥n), Estudios Sugeridos, Abordaje Terap√©utico (dosis), Signos Alarma, Fuentes."""
        elif special_command == "study_mode":
            return self._get_base_prompt(domain) + "\n\n**MODO EDUCATIVO**: Usa analog√≠as, ejemplos cl√≠nicos, explica 'por qu√©', divide conceptos, casos pr√°cticos, errores comunes, correlaci√≥n cl√≠nica. Objetivo: ENTENDER profundamente."
        else:
            return self._get_base_prompt(domain)

    def _get_base_prompt(self, domain):
        return f"""Eres Lisabella, asistente m√©dico en {domain}.\n\n**ESTRUCTURA**: Definici√≥n, Detalles Clave (tablas/listas), Advertencias, Fuentes.\n\n**REGLAS**: Rigor cient√≠fico, terminolog√≠a precisa, NO inventes.\n\n**FUENTES V√ÅLIDAS**: Gray's, Netter, Guyton, Robbins, Harrison's, UpToDate, Mayo, ESC/AHA/COFEPRIS, NEJM, Lancet, JAMA.\n\nConciso pero completo. Profundidad acad√©mica con claridad."""

    def _build_user_prompt(self, question, domain, special_command=None):
        if special_command in ["revision_nota", "correccion_nota", "elaboracion_nota", "valoracion"]:
            return question
        return f"""PREGUNTA M√âDICA ({domain}):\n{question}\n\nEstructura: Definici√≥n, Detalles Clave, Advertencias, Fuentes"""

    def _generate_rate_limit_message(self):
        return "‚è≥ **Sistema Saturado**\n\nEspera 1-2 minutos. L√≠mite t√©cnico del servicio."