import os
import time
from concurrent.futures import ThreadPoolExecutor, TimeoutError
from groq import Groq
from typing import Optional

# Intentar importar RAG (opcional)
try:
    from src.rag_engine import RAGEngine
    RAG_AVAILABLE = True
except ImportError:
    RAG_AVAILABLE = False
    print("‚ö†Ô∏è RAG Engine no disponible - funcionando sin base de conocimiento")

class GroqClient:
    def __init__(self):
        api_key = os.environ.get("GROQ_API_KEY")
        if not api_key:
            raise Exception("GROQ_API_KEY no configurada")
        self.client = Groq(api_key=api_key)
        self.model = os.environ.get("GROQ_MODEL", "llama-3.3-70b-versatile")
        self.temp = float(os.environ.get("GROQ_TEMP", "0.3"))
        self.max_retries = 3
        self.base_retry_delay = 2
        self.api_timeout = 300
        
        # Inicializar RAG si est√° disponible
        self.rag_engine = None
        if RAG_AVAILABLE:
            try:
                self.rag_engine = RAGEngine()
                print(f"‚úÖ RAG Engine inicializado: {self.rag_engine.get_stats()}")
            except Exception as e:
                print(f"‚ö†Ô∏è Error al inicializar RAG: {e}")

    def _classify_question_type(self, question: str) -> str:
        q_lower = (question or "").lower()
        if any(word in q_lower for word in ["dosis", "calcular", "cuanto", "cu√°nto", "que es", "qu√© es", "define", "definici√≥n", "definicion", "posologia", "posolog√≠a"]):
            return "operativa"
        if q_lower.count("‚Ä¢") >= 3 or q_lower.count("\n") >= 3 or any(kw in q_lower for kw in ["incluyendo:", "incluye:"]):
            return "academica"
        return "estandar"

    def _log_token_usage(self, prompt_tokens, completion_tokens, domain):
        total = (prompt_tokens or 0) + (completion_tokens or 0)
        timestamp = time.strftime("%Y-%m-%d %H:%M:%S")
        print(f"üìä [{timestamp}] Tokens: P={prompt_tokens} + C={completion_tokens} = {total} | Dominio: {domain}")
        try:
            os.makedirs("logs", exist_ok=True)
            with open("logs/token_usage.log", "a", encoding="utf-8") as f:
                f.write(f"{timestamp}|{domain}|{prompt_tokens}|{completion_tokens}|{total}\n")
        except Exception:
            pass

    def generate_stream(self, question, domain, special_command=None):
        # Buscar contexto en RAG si est√° disponible
        rag_context = self._get_rag_context(question) if self.rag_engine else None
        
        system_msg = self._build_system_prompt(domain, special_command, rag_context)
        user_msg = self._build_user_prompt(question, domain, special_command)
        question_type = self._classify_question_type(question)
        # Aumentar tokens para permitir respuestas completas sin alucinaciones
        if question_type == "operativa":
            max_tokens, temperature = 1500, 0.1  # Dosis, c√°lculos - m√°s espacio para explicar
        elif question_type == "academica":
            max_tokens, temperature = 12000, 0.3  # Preguntas complejas - sin l√≠mite artificial
        else:
            max_tokens, temperature = 6000, 0.3  # Preguntas est√°ndar - espacio generoso
        if special_command in ["revision_nota", "correccion_nota", "elaboracion_nota", "valoracion"]:
            max_tokens, temperature = 16000, 0.1  # Notas m√©dicas - m√°xima capacidad
        try:
            stream = self.client.chat.completions.create(
                model=self.model,
                messages=[{"role": "system", "content": system_msg}, {"role": "user", "content": user_msg}],
                temperature=temperature,
                max_tokens=max_tokens,
                stream=True,
            )
            chunk_count, accumulated_content = 0, ""
            for event in stream:
                choices = getattr(event, "choices", [])
                if choices:
                    delta = getattr(choices[0].delta, "content", None)
                    if delta:
                        chunk_count += 1
                        accumulated_content += delta
                        yield delta
            self._log_token_usage(len(system_msg + user_msg) // 4, len(accumulated_content) // 4, domain)
            yield "__STREAM_DONE__"
        except Exception as e:
            error_str, error_lower = str(e), str(e).lower()
            if "429" in error_str or "rate" in error_lower:
                yield "\n\n‚è≥ **Sistema Saturado**\n\nEspera 1-2 minutos."
            elif "timeout" in error_lower:
                yield "\n\n‚è±Ô∏è **Timeout**\n\nIntenta con pregunta m√°s breve."
            elif "401" in error_str or "auth" in error_lower:
                yield "\n\n‚ö†Ô∏è **Error autenticaci√≥n**\n\nContacta administrador."
            else:
                yield f"\n\n‚ö†Ô∏è **Error**\n\n{error_str[:200]}"
            yield "__STREAM_DONE__"

    def generate(self, question, domain, special_command=None):
        question_type = self._classify_question_type(question)
        # Aumentar tokens para calidad sin alucinaciones
        max_tokens = 1500 if question_type == "operativa" else (12000 if question_type == "academica" else 6000)
        if special_command in ["revision_nota", "correccion_nota", "elaboracion_nota", "valoracion"]:
            max_tokens = 16000
        for attempt in range(self.max_retries):
            try:
                with ThreadPoolExecutor(max_workers=1) as executor:
                    return executor.submit(self._call_groq_api, question, domain, special_command, max_tokens).result(timeout=self.api_timeout)
            except TimeoutError:
                if attempt < self.max_retries - 1:
                    time.sleep(self.base_retry_delay)
                else:
                    return "‚è±Ô∏è **Timeout**\nReformula tu pregunta."
            except Exception as e:
                if attempt < self.max_retries - 1 and ("429" in str(e) or "rate" in str(e).lower()):
                    time.sleep(self.base_retry_delay * (2 ** attempt))
                else:
                    return f"‚ö†Ô∏è **Error**: {str(e)[:200]}"
        return "‚è≥ **Sistema Saturado**"

    def _call_groq_api(self, question, domain, special_command, max_tokens=3000):
        # Buscar contexto en RAG si est√° disponible
        rag_context = self._get_rag_context(question) if self.rag_engine else None
        
        system_msg = self._build_system_prompt(domain, special_command, rag_context)
        user_msg = self._build_user_prompt(question, domain, special_command)
        temperature = 0.1 if special_command in ["revision_nota", "correccion_nota", "elaboracion_nota", "valoracion"] else self.temp
        response = self.client.chat.completions.create(
            model=self.model,
            messages=[{"role": "system", "content": system_msg}, {"role": "user", "content": user_msg}],
            temperature=temperature,
            max_tokens=max_tokens,
        )
        usage = getattr(response, "usage", None)
        if usage:
            try:
                self._log_token_usage(getattr(usage, "prompt_tokens", 0), getattr(usage, "completion_tokens", 0), domain)
            except Exception:
                pass
        return response.choices[0].message.content

    def generate_chunk(self, prompt: str, domain: str, max_tokens: int = 1200):
        system_msg = self._get_base_prompt(domain)
        response = self.client.chat.completions.create(
            model=self.model,
            messages=[{"role": "system", "content": system_msg}, {"role": "user", "content": prompt}],
            temperature=self.temp,
            max_tokens=max_tokens,
        )
        return response.choices[0].message.content

    def _get_rag_context(self, question: str) -> Optional[str]:
        """Buscar contexto relevante en la base de conocimiento RAG"""
        if not self.rag_engine:
            return None
        
        try:
            context = self.rag_engine.get_context_for_query(question, min_relevance=0.7)
            if context:
                print(f"üìö RAG: Contexto encontrado para '{question[:50]}...'")
            return context
        except Exception as e:
            print(f"‚ö†Ô∏è Error en RAG search: {e}")
            return None
    
    def _build_system_prompt(self, domain, special_command=None, rag_context=None):
        if special_command == "revision_nota":
            return """Eres auditor m√©dico JCI/COFEPRIS. Eval√∫a nota con est√°ndares completos: datos paciente, motivo consulta, padecimiento, antecedentes, exploraci√≥n, diagn√≥stico, plan, legal. Formato: Componentes Presentes, Faltantes, Errores, Cumplimiento %, Recomendaciones."""
        elif special_command == "correccion_nota":
            return """Corrector notas m√©dicas JCI/COFEPRIS. Detecta errores formato, ortograf√≠a m√©dica, dosis, claridad. Formato: Errores Detectados, Nota Corregida, Sugerencias. NO inventes datos."""
        elif special_command == "elaboracion_nota":
            return """Genera plantilla SOAP completa: Datos Documento, Datos Paciente, Subjetivo (motivo/padecimiento/antecedentes), Objetivo (vitales/exploraci√≥n), An√°lisis (diagn√≥stico/justificaci√≥n), Plan (estudios/tratamiento/pron√≥stico/seguimiento). Marca [COMPLETAR] si falta info."""
        elif special_command == "valoracion":
            return """M√©dico consultor Mayo/UpToDate. Proporciona: Resumen Caso, Hip√≥tesis Diagn√≥sticas (probable + 3 diferenciales con justificaci√≥n), Estudios Sugeridos, Abordaje Terap√©utico (dosis), Signos Alarma, Fuentes."""
        elif special_command == "study_mode":
            return self._get_base_prompt(domain) + "\n\n**MODO EDUCATIVO**: Usa analog√≠as, ejemplos cl√≠nicos, explica 'por qu√©', divide conceptos, casos pr√°cticos, errores comunes, correlaci√≥n cl√≠nica. Objetivo: ENTENDER profundamente."
        else:
            return self._get_base_prompt(domain)

    def _get_base_prompt(self, domain, rag_context=None):
        base = f"""Eres Lisabella, asistente m√©dico especializado en {domain}.

{rag_context if rag_context else ''}

""" if rag_context else f"""Eres Lisabella, asistente m√©dico especializado en {domain}.

"""
        
        return base + """

**ESTRUCTURA OBLIGATORIA**:
1. **Definici√≥n/Concepto**: Breve y precisa
2. **Detalles Clave**: 
   - Anatom√≠a: Espec√≠fica (ligamentos, relaciones, irrigaci√≥n arterial/venosa, drenaje linf√°tico, inervaci√≥n)
   - Fisiopatolog√≠a: Mecanismos moleculares y celulares
   - Cl√≠nica: Manifestaciones, diagn√≥stico, tratamiento con dosis exactas
3. **Puntos Cr√≠ticos**: Complicaciones, contraindicaciones, signos de alarma
4. **Razonamiento Cl√≠nico**: Integraci√≥n y juicio cl√≠nico
5. **Referencias**: OBLIGATORIO - Cita fuentes verificables

**REGLAS ESTRICTAS**:
‚Ä¢ Rigor cient√≠fico absoluto - terminolog√≠a m√©dica precisa
‚Ä¢ NO inventes datos, dosis, ni referencias
‚Ä¢ En anatom√≠a: s√© espec√≠fico (ej: "Ligamento esplenorrenal contiene vasos espl√©nicos")
‚Ä¢ En farmacolog√≠a: dosis exactas con v√≠a y frecuencia
‚Ä¢ S√© conciso pero completo - evita redundancia
‚Ä¢ Usa tablas/listas para organizar informaci√≥n compleja

**REFERENCIAS (OBLIGATORIO AL FINAL)**:
‚Ä¢ SIEMPRE incluye secci√≥n de referencias al final
‚Ä¢ SOLO cita fuentes que realmente contengan esa informaci√≥n
‚Ä¢ Formato: "**Referencias**: [Fuente] - [Tema espec√≠fico]"
‚Ä¢ Fuentes verificables: Gray's Anatomy, Netter, Moore Anatom√≠a, Guyton & Hall, Robbins, Harrison's, UpToDate, Gu√≠as ESC/AHA/ACC/COFEPRIS
‚Ä¢ Si no tienes certeza absoluta de la fuente, indica: "**Basado en**: Principios de [√°rea] establecidos en literatura m√©dica est√°ndar"

Profundidad R3-R4. Precisi√≥n quir√∫rgica.

**FILOSOF√çA ANTI-ALUCINACI√ìN**:
‚Ä¢ Si NO tienes la informaci√≥n exacta, adm√≠telo claramente
‚Ä¢ NUNCA inventes dosis, procedimientos o referencias
‚Ä¢ Es mejor decir "No tengo acceso a la fuente espec√≠fica" que inventar
‚Ä¢ Prioriza CALIDAD y PRECISI√ìN sobre completitud
‚Ä¢ Usa todo el espacio necesario - no hay l√≠mite de tokens si la respuesta lo requiere"""

    def _build_user_prompt(self, question, domain, special_command=None):
        if special_command in ["revision_nota", "correccion_nota", "elaboracion_nota", "valoracion"]:
            return question
        return f"""PREGUNTA M√âDICA ({domain}):\n{question}\n\nResponde con razonamiento cl√≠nico s√≥lido. S√© preciso, conciso y t√©cnico."""

    def _generate_rate_limit_message(self):
        return "‚è≥ **Sistema Saturado**\n\nEspera 1-2 minutos. L√≠mite t√©cnico del servicio."
